'''
Author: Maonan Wang
Date: 2025-04-23 15:13:54
Description: VLMLight, åœºæ™¯ç†è§£+å†³ç­– (æ ¹æ®é«˜ç²¾åº¦æ¸²æŸ“ç»“æœåˆ¤æ–­)
LastEditTime: 2025-07-29 19:46:02
LastEditors: WANG Maonan
'''
import os
import json
import subprocess

from qwen_agent.agents import GroupChat
from qwen_agent.utils.output_beautify import typewriter_print
from utils.tsc_agent.llm_agents import (
    scene_understanding_agent, # å›¾åƒç†è§£ Agent
    scene_analysis_agent, # åœºæ™¯åˆ†æ Agent
    rl_agent, # rl agent
    ConcernCaseAgent, # group agents
    llm_cfg
)

# 3D TSC ENV
import re
import cv2
import torch
import numpy as np

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import VecNormalize, SubprocVecEnv

from tshub.utils.get_abs_path import get_abs_path
from tshub.utils.init_log import set_logger

from _config import SCENARIO_CONFIGS
from utils.make_tsc_env import make_env
from utils.tools import (
    save_to_json, 
    create_folder,
    append_response_to_file,
)

def convert_rgb_to_bgr(image):
    # Convert an RGB image to BGR
    return image[:, :, ::-1]

path_convert = get_abs_path(__file__)
set_logger(path_convert('./'))

def extract_action(response):
    """å°†å›å¤ä¸­çš„æ–‡æœ¬è½¬æ¢ä¸º Traffic Phase è¿›è¡Œä¸‹å‘, å¦‚æœä¸åˆè§„, åˆ™ä½¿ç”¨ RL çš„åŠ¨ä½œ
    """
    match = re.search(r'\d+', response)
    if match:
        return np.array([int(match.group())])
    raise ValueError("No number found in the given string.")


def render_timestep(timestep_folder, scenario_name):
    """è°ƒç”¨å¤–éƒ¨æ¸²æŸ“è„šæœ¬æ¸²æŸ“å•ä¸ªæ—¶é—´æ­¥"""
    blender_file = path_convert(f"../sim_envs/{scenario_name}/env.blend")
    render_script = path_convert("./render_single_timestep.py")
    command = [
        'blender',
        blender_file,
        '--background',
        '--python',
        render_script,
        '--',
        '--timestep_path', timestep_folder
    ]
    
    try:
        process = subprocess.run(
            command, 
            capture_output=True, 
            text=True,
            check=True
        )
        print(f"âœ… æ¸²æŸ“å®Œæˆ {timestep_folder}")
    except subprocess.CalledProcessError as e:
        print(f"ğŸ”¥ æ¸²æŸ“é”™è¯¯ {timestep_folder}:")
        print(e.stderr)
    except Exception as e:
        print(f"ğŸ”¥ æœªçŸ¥æ¸²æŸ“é”™è¯¯: {str(e)}")

# å…¨å±€å˜é‡
scenario_key = "Hongkong_YMT" # Hongkong_YMT, SouthKorea_Songdo, France_Massy
config = SCENARIO_CONFIGS.get(scenario_key) # è·å–ç‰¹å®šåœºæ™¯çš„é…ç½®
SCENARIO_NAME = config["SCENARIO_NAME"] # åœºæ™¯åç§°
NETFILE = config["NETFILE"] # sumocfg æ–‡ä»¶, åŠ è½½ eval æ–‡ä»¶
JUNCTION_NAME = config["JUNCTION_NAME"] # sumo net å¯¹åº”çš„è·¯å£ ID
PHASE_NUMBER = config["PHASE_NUMBER"] # ç»¿ç¯ç›¸ä½æ•°é‡
SENSOR_INDEX_2_PHASE_INDEX = config["SENSOR_INDEX_2_PHASE_INDEX"] # ä¼ æ„Ÿå™¨ä¸ Traffic Phase çš„å¯¹åº”å…³ç³»

# Init Agents
concer_case_decision_agent = ConcernCaseAgent(
    name='concer case decision agent',
    description='ä½ æ‰®æ¼”ä¸€ä¸ªåœ¨è·¯å£æŒ‡æŒ¥äº¤é€šçš„è­¦å¯Ÿï¼Œå½“è·¯å£å­˜åœ¨ç‰¹æ®Šè½¦è¾†ï¼Œä¾‹å¦‚è­¦è½¦ã€æ•‘æŠ¤è½¦å’Œæ¶ˆé˜²è½¦ç­‰æƒ…å†µéœ€è¦ä½ æ¥å†³ç­–ã€‚',
    llm_cfg=llm_cfg,
    phase_num=PHASE_NUMBER, # å½“å‰è·¯å£å­˜åœ¨çš„ç›¸ä½æ•°é‡
) 

agents = [rl_agent, concer_case_decision_agent]
group_decision_bots = GroupChat(
    llm=llm_cfg, 
    agents=agents,
    agent_selection_method='auto',
)


if __name__ == '__main__':
    # #########
    # Init Env
    # #########
    sumo_cfg = path_convert(f"../sim_envs/{SCENARIO_NAME}/{NETFILE}.sumocfg")
    scenario_glb_dir = path_convert(f"../sim_envs/{SCENARIO_NAME}/3d_assets/")
    trip_info = path_convert(f"./results/{SCENARIO_NAME}/tripinfo.out.xml") # åœºæ™¯æŒ‡æ ‡è¾“å‡º
    create_folder(path_convert(f"./results/{SCENARIO_NAME}/"))
    tls_add = [
        path_convert(f'../sim_envs/{SCENARIO_NAME}/add/e2.add.xml'), # æ¢æµ‹å™¨
        path_convert(f'../sim_envs/{SCENARIO_NAME}/add/tls_programs.add.xml'), # ä¿¡å·ç¯
    ]
    params = {
        'tls_id':JUNCTION_NAME,
        'num_seconds':600,
        'number_phases':PHASE_NUMBER,
        'sumo_cfg':sumo_cfg,
        'scenario_glb_dir': scenario_glb_dir, # åœºæ™¯ 3D ç´ æ
        'trip_info': trip_info, # è½¦è¾†ç»Ÿè®¡ä¿¡æ¯
        'tls_state_add': tls_add, # ä¿¡å·ç¯ç­–ç•¥
        'use_gui':True,
    }
    env = SubprocVecEnv([make_env(**params) for _ in range(1)])
    env = VecNormalize.load(load_path=path_convert(f'../rl_tsc/results/{SCENARIO_NAME}/models/last_vec_normalize.pkl'), venv=env)
    env.training = False # æµ‹è¯•çš„æ—¶å€™ä¸è¦æ›´æ–°
    env.norm_reward = False

    device = torch.device('cpu')
    model_path = path_convert(f'../rl_tsc/results/{SCENARIO_NAME}/models/last_rl_model.zip')
    model = PPO.load(model_path, env=env, device=device)

    # Simulation with environment
    obs = env.reset()
    sensor_datas = None # åˆå§‹ä¼ æ„Ÿå™¨æ•°æ®ä¸ºç©º, 
    dones = False # é»˜è®¤æ˜¯ False
    time_step = 0

    while not dones:
        rl_action, _state = model.predict(obs, deterministic=True) # RL è·å¾—çš„åŠ¨ä½œ
        rl_agent.update_rl_traffic_phase(new_phase=rl_action) # æ›´æ–°å½“å‰ RL æ¨èçš„åŠ¨ä½œ

        # ##########
        # æ–°å»ºæ–‡ä»¶å¤¹ (å­˜å‚¨æ¯ä¸€ä¸ª step çš„ä¿¡æ¯)
        # ##########
        time_step += 1 # è®°å½• timestep
        _save_folder = path_convert(f"./{SCENARIO_NAME}/{time_step}/")
        create_folder(_save_folder)
        _veh_json_file = os.path.join(_save_folder, 'data.json') # è½¦è¾†æ•°æ®
        _response_txt_file = os.path.join(_save_folder, 'response.txt') # LLM å›å¤

        if sensor_datas is None:
            obs, rewards, dones, infos = env.step(rl_action)

            # ##############################
            # è·å¾—å¹¶ä¿å­˜ä¼ æ„Ÿå™¨çš„æ•°æ® & è½¦è¾† JSON
            # ##############################
            sensor_datas = infos[0]['3d_data']

            # ä¿å­˜ 3D åœºæ™¯æ•°æ®
            vehicle_elements = sensor_datas['veh_elements'] # è½¦è¾†æ•°æ®
            save_to_json(vehicle_elements, _veh_json_file)

            # ä¿å­˜å›¾ç‰‡æ•°æ®
            sensor_data = sensor_datas['image'] # è·å¾—å›¾ç‰‡æ•°æ®
            for phase_index in range(PHASE_NUMBER):
                image_path = os.path.join(_save_folder, f"./{phase_index}.jpg") # ä¿å­˜çš„å›¾åƒæ•°æ®
                camera_data = sensor_data[f"{JUNCTION_NAME}_{phase_index}"]['junction_front_all']
                cv2.imwrite(image_path, convert_rgb_to_bgr(camera_data))
            
            # ç«‹å³æ¸²æŸ“å½“å‰æ—¶é—´æ­¥
            render_timestep(_save_folder, SCENARIO_NAME)

        else:
            # (1) ä¿å­˜ä¼ æ„Ÿå™¨æ•°æ®; (2) åœºæ™¯å›¾ç‰‡ç†è§£; (3) å°†å›¾åƒè¯¢é—® agents; (3) ä½¿ç”¨è¿™é‡Œçš„ decision ä¸ç¯å¢ƒäº¤äº’

            # ##############################
            # è·å¾—å¹¶ä¿å­˜ä¼ æ„Ÿå™¨çš„æ•°æ® & è½¦è¾† JSON
            # ##############################
            sensor_datas = infos[0]['3d_data']

            # ä¿å­˜ 3D åœºæ™¯æ•°æ®
            vehicle_elements = sensor_datas['veh_elements'] # è½¦è¾†æ•°æ®
            save_to_json(vehicle_elements, _veh_json_file)

            # ä¿å­˜å›¾ç‰‡æ•°æ® (low quality)
            sensor_data = sensor_datas['image'] # è·å¾—å›¾ç‰‡æ•°æ®
            for phase_index in range(PHASE_NUMBER):
                image_path = os.path.join(_save_folder, f"./{phase_index}.jpg") # ä¿å­˜çš„å›¾åƒæ•°æ®
                camera_data = sensor_data[f"{JUNCTION_NAME}_{phase_index}"]['junction_front_all']
                cv2.imwrite(image_path, convert_rgb_to_bgr(camera_data))

            # ç«‹å³æ¸²æŸ“å½“å‰æ—¶é—´æ­¥
            render_timestep(_save_folder, SCENARIO_NAME)

            # ###############
            # (2) åœºæ™¯å›¾ç‰‡ç†è§£
            # ###############
            junction_mem = {} # åˆ†åˆ«è®°å½•å¤šä¸ªè·¯å£çš„ä¿¡æ¯ (ä¸€ä¸ªè·¯å£ä¸åŒæ–¹å‘çš„ä¿¡æ¯)
            for scene_index in range(PHASE_NUMBER):
                messages = [] # å¯¹è¯çš„å†å²ä¿¡æ¯, è¿™é‡Œä¸åŒæ–¹å‘æ˜¯ç‹¬ç«‹çš„
                image_path = os.path.join(_save_folder, f"./high_quality_rgb/{scene_index}.png") # ä¿å­˜çš„å›¾åƒæ•°æ®
                # æ„é€ å¤šæ¨¡æ€è¾“å…¥
                content = [{"text": "å›¾ç‰‡ä¸ºè·¯å£æ‘„åƒå¤´ï¼Œè¯·ä½ å¯¹å½“å‰é“è·¯è¿›è¡Œæè¿°ï¼ŒåŒ…æ‹¬æ‹¥å µç¨‹åº¦ï¼Œä»¥åŠæ˜¯å¦å­˜åœ¨ç‰¹æ®Šè½¦è¾†ã€‚å¦‚æœæ²¡æœ‰æ˜æ˜¾çš„æ ‡å¿—ï¼Œåˆ™ä¸ºæ™®é€šè½¦è¾†ï¼Œåªæœ‰ååˆ†ç¡®å®šæ˜¯ç‰¹æ®Šè½¦è¾†æ‰è¿›è¡ŒæŒ‡å‡ºï¼Œå…¶ä½™è½¦è¾†éƒ½æ˜¯æ™®é€šè½¦è¾†ã€‚å¦‚æœå­˜åœ¨ç‰¹æ®Šè½¦è¾†ï¼Œä½ éœ€è¦è¿›ä¸€æ­¥åˆ¤æ–­è½¦è¾†æ­£åœ¨é©¶å…¥è·¯å£è¿˜æ˜¯é©¶å‡ºï¼Œæ˜¯å¦å·²ç»ç»è¿‡äº†åœè½¦çº¿ã€‚åªæœ‰é©¶å…¥ä¸”åœ¨è·¯å£å†…çš„è½¦è¾†æ‰éœ€è¦è€ƒè™‘ã€‚"}]
                content.append({'image': image_path})
                messages.append({
                    'role': 'user',
                    'content': content  # å¤šæ¨¡æ€çš„è¾“å…¥
                })  # Append the user query to the chat history.

                # AI Agents å¯¹å›¾ç‰‡è¿›è¡Œè§£æ
                response = []
                response_plain_text = ''
                print(f'-->Scene Understand Agent response for Scene-{scene_index}:')
                for response in scene_understanding_agent.run(messages=messages):
                    response_plain_text = typewriter_print(response, response_plain_text)
                response_plain_text = f'-->Scene Understand Agent response for Scene-{scene_index}:\n' + response_plain_text
                append_response_to_file(file_path=_response_txt_file, content=response_plain_text)
                print('\n---------\n')
                # Append the bot responses to the chat history.
                junction_mem[scene_index] = response[0]['content'] # æ¯ä¸ªæ–¹å‘çš„ä¿¡æ¯

            # ##################
            # (3) åœºæ™¯ä¿¡æ¯åˆ†æ
            # ##################
            junction_description = ""
            for scene_index, scene_text in junction_mem.items():
                traffic_phase_index = SENSOR_INDEX_2_PHASE_INDEX[scene_index] # ä¼ æ„Ÿå™¨ Index è½¬æ¢ä¸º Traffic Phase Index
                junction_description += f"Traffic Phase-{traffic_phase_index} å¯¹åº”çš„äº¤é€šæƒ…å†µä¸ºï¼š{scene_text}ï¼›\n"
            
            # æ„å»ºè¯¢é—®çš„ä¿¡æ¯
            messages = []
            messages.append({
                'role': 'user',
                'content': f"ä¸‹é¢åˆ†åˆ«æ˜¯ä¸€ä¸ªåå­—è·¯å£ä¸­ {PHASE_NUMBER} ä¸ª Traffic Phase çš„æè¿°ï¼Œè¯·ä½ æ ¹æ®è¯¦ç»†çš„æè¿°æ€»ç»“æ¯ä¸ª Traffic Phase çš„ä¿¡æ¯ï¼Œåªéœ€è¦æ€»ç»“æ‹¥å µæƒ…å†µå’Œæ˜¯å¦æœ‰ç‰¹æ®Šè½¦è¾†ï¼Œéœ€è¦æ¦‚å†µã€‚å¦‚æœæ— æ³•è¾¨åˆ«è½¦è¾†ç±»å‹ï¼Œé»˜è®¤æ˜¯æ™®é€šè½¦è¾†ã€‚ä¸éœ€è¦ç–‘ä¼¼ç‰¹æ®Šè½¦è¾†ã€‚" + \
                    f"ä¸‹é¢æ˜¯å½“å‰æ¯ä¸€ä¸ª Traffic Phase è¯¦ç»†çš„æè¿°ï¼š\n{junction_description}"
            })
            response = []
            response_plain_text = ''
            print(f'-->Scene Analysis Agent response:')
            for response in scene_analysis_agent.run(messages=messages):
                response_plain_text = typewriter_print(response, response_plain_text)
            append_response_to_file(file_path=_response_txt_file, content=response_plain_text)

            # ###################
            # (4) æ ¹æ®åœºæ™¯è¿›è¡Œå†³ç­–
            # ###################
            messages = []
            messages.append({
                'role': 'user',
                'content': f"è¯·ä½ æ ¹æ®å½“å‰æ¯ä¸€ä¸ª Traffic Phase çš„çŠ¶æ€ï¼Œåšå‡ºå†³ç­–ï¼Œä»è€Œæ¥æ§åˆ¶ä¿¡å·ç¯ã€‚å½“å‰ Traffic Phase çš„ä¿¡æ¯å¦‚ä¸‹ï¼š\n{response[0]['content']}ã€‚"
            })
            response = []
            response_plain_text = ''
            print(f'\n-->Group Decision Agent response:')
            for response in group_decision_bots.run(messages=messages, max_round=1):
                response_plain_text = typewriter_print(response, response_plain_text)
            append_response_to_file(file_path=_response_txt_file, content=response_plain_text)

            # (5) response -> action
            response_dict = json.loads(response[-1]['content'])
            decision, explanation = response_dict['decision'], response_dict['explanation']

            try:
                # å¦‚æœåˆè§„, åˆ™ä½¿ç”¨ LLM çš„ action
                action = extract_action(decision) # å†³ç­–è½¬æ¢ä¸ºåŠ¨ä½œ
            except:
                # (6) å¦‚æœ action ä¸åˆè§„, åˆ™ä½¿ç”¨ RL
                action = rl_action

            obs, rewards, dones, infos = env.step(action)

    env.close()