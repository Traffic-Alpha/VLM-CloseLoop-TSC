'''
Author: Maonan Wang
Date: 2025-04-23 15:13:54
LastEditTime: 2025-07-30 15:48:26
LastEditors: WANG Maonan
Description: VLMLight
'''
# AI Agents
import os
import json
from qwen_agent.utils.output_beautify import typewriter_print
from utils.tsc_agent.llm_agents import (
    scene_understanding_agent, # å›¾åƒç†è§£ Agent
    scene_analysis_agent, # åœºæ™¯åˆ†æž Agent
    ConcernCaseAgent,
    mode_select_agent,
    llm_cfg
)

# 3D TSC ENV
import re
import cv2
import time
import torch
import numpy as np

from stable_baselines3 import PPO
from stable_baselines3.common.vec_env import VecNormalize, SubprocVecEnv

from tshub.utils.get_abs_path import get_abs_path
from tshub.utils.init_log import set_logger
from utils.make_tsc_env import make_env
from _config import SCENARIO_CONFIGS
from utils.tools import (
    save_to_json, 
    create_folder,
    append_response_to_file,
)

def convert_rgb_to_bgr(image):
    # Convert an RGB image to BGR
    return image[:, :, ::-1]

path_convert = get_abs_path(__file__)
set_logger(path_convert('./'))

def extract_action(response):
    """å°†å›žå¤ä¸­çš„æ–‡æœ¬è½¬æ¢ä¸º Traffic Phase è¿›è¡Œä¸‹å‘
    """
    match = re.search(r'\d+', response)
    if match:
        return np.array([int(match.group())])
    raise ValueError("No number found in the given string.")

def waiting_render(save_folder):
    # åˆ›å»ºå°±ç»ªæ ‡è®°æ–‡ä»¶ (è½¬å‘ blender)
    ready_file = os.path.join(save_folder, '../.ready') # åœ¨åœºæ™¯æ ¹ç›®å½•ä¸‹
    task_info = {
        'timestep_path': _save_folder,
        'scenario_name': SCENARIO_NAME
    }
    with open(ready_file, 'w') as f:
        json.dump(task_info, f)
    print(f"â±ï¸ æ—¶é—´æ­¥ {time_step} æ•°æ®å°±ç»ªï¼Œç­‰å¾…æ¸²æŸ“...")
    
    # ç­‰å¾…æ¸²æŸ“å®Œæˆ --> ç»§ç»­ä»¿çœŸ
    done_file = os.path.join(save_folder, '../.done')
    while not os.path.exists(done_file):
        time.sleep(1)  # æ¯ç§’æ£€æŸ¥ä¸€æ¬¡
    print(f"ðŸ–¼ï¸ æ—¶é—´æ­¥ {time_step} æ¸²æŸ“å®Œæˆï¼Œç»§ç»­ä»¿çœŸ...")
    os.remove(done_file) # åˆ é™¤å°±ç»ªæ ‡è®°

# å…¨å±€å˜é‡
scenario_key = "Hongkong_YMT" # Hongkong_YMT, SouthKorea_Songdo, France_Massy
config = SCENARIO_CONFIGS.get(scenario_key) # èŽ·å–ç‰¹å®šåœºæ™¯çš„é…ç½®
SCENARIO_NAME = config["SCENARIO_NAME"] # åœºæ™¯åç§°
NETFILE = config["NETFILE"] # sumocfg æ–‡ä»¶, åŠ è½½ eval æ–‡ä»¶
JUNCTION_NAME = config["JUNCTION_NAME"] # sumo net å¯¹åº”çš„è·¯å£ ID
PHASE_NUMBER = config["PHASE_NUMBER"] # ç»¿ç¯ç›¸ä½æ•°é‡
SENSOR_INDEX_2_PHASE_INDEX = config["SENSOR_INDEX_2_PHASE_INDEX"] # ä¼ æ„Ÿå™¨ä¸Ž Traffic Phase çš„å¯¹åº”å…³ç³»

# Init Agents
concer_case_decision_agent = ConcernCaseAgent(
    name='concer case decision agent',
    description=(
        'You will roleplay as a traffic police officer directing vehicles at an intersection.'
        'Your task is to make decisions when special vehicles (such as police cars, ambulances, or fire trucks) approach the crossing, prioritizing their passage while maintaining overall traffic order.'
    ),
    llm_cfg=llm_cfg,
    phase_num=PHASE_NUMBER, # å½“å‰è·¯å£å­˜åœ¨çš„ç›¸ä½æ•°é‡
) 

if __name__ == '__main__':
    # #########
    # Init Env
    # #########
    sumo_cfg = path_convert(f"../sim_envs/{SCENARIO_NAME}/{NETFILE}.sumocfg")
    scenario_glb_dir = path_convert(f"../sim_envs/{SCENARIO_NAME}/3d_assets/")
    trip_info = path_convert(f"./results/{SCENARIO_NAME}/tripinfo.out.xml")
    create_folder(path_convert(f"./results/{SCENARIO_NAME}/"))
    tls_add = [
        path_convert(f'../sim_envs/{SCENARIO_NAME}/add/e2.add.xml'), # æŽ¢æµ‹å™¨
        path_convert(f'../sim_envs/{SCENARIO_NAME}/add/tls_programs.add.xml'), # ä¿¡å·ç¯
    ]
    params = {
        'tls_id':JUNCTION_NAME,
        'num_seconds':600,
        'number_phases':PHASE_NUMBER,
        'sumo_cfg':sumo_cfg,
        'scenario_glb_dir': scenario_glb_dir, # åœºæ™¯ 3D ç´ æ
        'trip_info': trip_info, # è½¦è¾†ç»Ÿè®¡ä¿¡æ¯
        'tls_state_add': tls_add, # ä¿¡å·ç¯ç­–ç•¥
        'use_gui':True,
    }
    env = SubprocVecEnv([make_env(**params) for _ in range(1)])
    env = VecNormalize.load(load_path=path_convert(f'../rl_tsc/results/{SCENARIO_NAME}/models/last_vec_normalize.pkl'), venv=env)
    env.training = False # æµ‹è¯•çš„æ—¶å€™ä¸è¦æ›´æ–°
    env.norm_reward = False

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model_path = path_convert(f'../rl_tsc/results/{SCENARIO_NAME}/models/last_rl_model.zip')
    model = PPO.load(model_path, env=env, device=device)

    # Simulation with environment
    obs = env.reset()
    sensor_datas = None # åˆå§‹ä¼ æ„Ÿå™¨æ•°æ®ä¸ºç©º, 
    dones = False # é»˜è®¤æ˜¯ False
    time_step = 0

    while not dones:
        rl_action, _state = model.predict(obs, deterministic=True) # RL èŽ·å¾—çš„åŠ¨ä½œ

        # ##########
        # æ–°å»ºæ–‡ä»¶å¤¹ (å­˜å‚¨æ¯ä¸€ä¸ª step çš„ä¿¡æ¯)
        # ##########
        time_step += 1
        _save_folder = path_convert(f"./{SCENARIO_NAME}/{time_step}/")
        create_folder(_save_folder) # æ¯æ¬¡äº¤äº’å­˜å‚¨å¯¹è¯
        _veh_json_file = os.path.join(_save_folder, 'data.json') # è½¦è¾†æ•°æ®
        _response_txt_file = os.path.join(_save_folder, 'response.txt') # LLM å›žå¤

        if sensor_datas is None:
            obs, rewards, dones, infos = env.step(rl_action)

            # ##############################
            # èŽ·å¾—å¹¶ä¿å­˜ä¼ æ„Ÿå™¨çš„æ•°æ® & è½¦è¾† JSON
            # ##############################
            sensor_datas = infos[0]['3d_data']

            # ä¿å­˜ 3D åœºæ™¯æ•°æ®
            vehicle_elements = sensor_datas['veh_elements'] # è½¦è¾†æ•°æ®
            save_to_json(vehicle_elements, _veh_json_file)

            # ä¿å­˜å›¾ç‰‡æ•°æ®
            sensor_data = sensor_datas['image'] # èŽ·å¾—å›¾ç‰‡æ•°æ®
            for phase_index in range(PHASE_NUMBER):
                image_path = os.path.join(_save_folder, f"./{phase_index}.jpg") # ä¿å­˜çš„å›¾åƒæ•°æ®
                camera_data = sensor_data[f"{JUNCTION_NAME}_{phase_index}"]['junction_front_all']
                cv2.imwrite(image_path, convert_rgb_to_bgr(camera_data))

            # ç­‰å¾…æ¸²æŸ“
            waiting_render(_save_folder)

        else:
            # (1) ä¿å­˜ä¼ æ„Ÿå™¨æ•°æ®; (2) åœºæ™¯å›¾ç‰‡ç†è§£; (3) å°†å›¾åƒè¯¢é—® agents; (3) ä½¿ç”¨è¿™é‡Œçš„ decision ä¸ŽçŽ¯å¢ƒäº¤äº’

            # ##############################
            # èŽ·å¾—å¹¶ä¿å­˜ä¼ æ„Ÿå™¨çš„æ•°æ® & è½¦è¾† JSON
            # ##############################
            sensor_datas = infos[0]['3d_data']

            # ä¿å­˜ 3D åœºæ™¯æ•°æ®
            vehicle_elements = sensor_datas['veh_elements'] # è½¦è¾†æ•°æ®
            save_to_json(vehicle_elements, _veh_json_file)

            # ä¿å­˜å›¾ç‰‡æ•°æ®
            sensor_data = sensor_datas['image'] # èŽ·å¾—å›¾ç‰‡æ•°æ®
            for phase_index in range(PHASE_NUMBER):
                image_path = os.path.join(_save_folder, f"./{phase_index}.jpg") # ä¿å­˜çš„å›¾åƒæ•°æ®
                camera_data = sensor_data[f"{JUNCTION_NAME}_{phase_index}"]['junction_front_all']
                cv2.imwrite(image_path, convert_rgb_to_bgr(camera_data))

            # ç­‰å¾…æ¸²æŸ“
            waiting_render(_save_folder)

            # ###############
            # (2) åœºæ™¯å›¾ç‰‡ç†è§£
            # ###############
            junction_mem = {} # åˆ†åˆ«è®°å½•å¤šä¸ªè·¯å£çš„ä¿¡æ¯ (ä¸€ä¸ªè·¯å£ä¸åŒæ–¹å‘çš„ä¿¡æ¯)
            for scene_index in range(PHASE_NUMBER):
                messages = [] # å¯¹è¯çš„åŽ†å²ä¿¡æ¯, è¿™é‡Œä¸åŒæ–¹å‘æ˜¯ç‹¬ç«‹çš„
                image_path = os.path.join(_save_folder, f"./high_quality_rgb/{scene_index}.png") # ä¿å­˜çš„å›¾åƒæ•°æ®
                # æž„é€ å¤šæ¨¡æ€è¾“å…¥
                content = [
                    {
                        "text": (
                            "The image shows a traffic intersection from a surveillance camera;" 
                            "describe the current road conditions, including the level of congestion and whether any special vehicles (such as police cars, ambulances, or fire trucks) are presentâ€”only identify a vehicle as special if it has clear markings and is approaching the intersection, "
                            "otherwise classify it as a regular vehicle; disregard vehicles that are too far from the intersection or not heading toward it."
                        )
                    }
                ]
                content.append({'image': image_path})
                messages.append({
                    'role': 'user',
                    'content': content  # å¤šæ¨¡æ€çš„è¾“å…¥
                })  # Append the user query to the chat history.

                # AI Agents å¯¹å›¾ç‰‡è¿›è¡Œè§£æž
                response = []
                response_plain_text = ''
                print(f'-->Scene Understand Agent response for Scene-{scene_index}:')
                for response in scene_understanding_agent.run(messages=messages):
                    response_plain_text = typewriter_print(response, response_plain_text)
                response_plain_text = f'-->Scene Understand Agent response for Scene-{scene_index}:\n' + response_plain_text
                append_response_to_file(file_path=_response_txt_file, content=response_plain_text)
                print('\n---------\n')
                # Append the bot responses to the chat history.
                junction_mem[scene_index] = response[0]['content'] # æ¯ä¸ªæ–¹å‘çš„ä¿¡æ¯

            # ##################
            # (3) åœºæ™¯ä¿¡æ¯åˆ†æž
            # ##################
            # ç»„åˆæˆæ¯ä¸€ä¸ª traffic phase çš„ä¿¡æ¯
            junction_description = f"The traffic signal you control has {PHASE_NUMBER} Traffic Phases:\n"
            for scene_index, scene_text in junction_mem.items():
                traffic_phase_index = SENSOR_INDEX_2_PHASE_INDEX[scene_index]
                junction_description += f"â€¢ Phase-{traffic_phase_index}: {scene_text}\n"
            
            # æž„å»ºè¯¢é—®çš„ä¿¡æ¯ --> æ€»ç»“è·¯å£æƒ…å†µ, ä¸æŒ‰ç…§ traffic phase æ€»ç»“
            messages = []
            messages.append({
                'role': 'user',
                'content': (
                    "Analyze the entire junction description below to determine ONE of these two conditions:\n"
                    "1. 'Special traffic condition' - ONLY if at least one clearly confirmed emergency vehicle (police/ambulance/fire truck) is present\n"
                    "2. 'Normal traffic condition' - if NO confirmed emergency vehicles are present;\n"
                    "Rules:\n"
                    "- Report ONLY the final condition ('Special traffic condition' or 'Normal traffic condition')\n"
                    "- Consider ONLY visually confirmed emergency vehicles (ignore suspected/unidentified special vehicles)\n"
                    "- Ignore all other factors: congestion levels, regular vehicles, traffic phases\n"
                    "- Default to 'Normal traffic condition' if uncertain\n"
                    f"Junction description: \n{junction_description}"
                )
            })

            response = []
            response_plain_text = ''
            print(f'-->Scene Analysis Agent response:')
            for response in scene_analysis_agent.run(messages=messages):
                response_plain_text = typewriter_print(response, response_plain_text)
            response_plain_text = f'-->Scene Analysis Agent response:\n' + response_plain_text
            append_response_to_file(file_path=_response_txt_file, content=response_plain_text)

            # ###################
            # (4) å¿«æ…¢åˆ†æ”¯çš„é€‰æ‹©
            # ###################
            junction_summary = response[0]['content'] # è·¯å£åœºæ™¯æ€»ç»“
            messages = []
            messages.append({
                'role': 'user',
                'content': f"Based on the current status of the junction, select the which agent to use. Now the junction is under \n{junction_summary}."
            })
            response = []
            response_plain_text = ''
            print(f'\n-->Mode Select Agent response:')
            for response in mode_select_agent.run(messages=messages):
                response_plain_text = typewriter_print(response, response_plain_text)
            response_plain_text = f'-->Mode Select Agent response:\n' + response_plain_text
            append_response_to_file(file_path=_response_txt_file, content=response_plain_text)

            # ##############
            # (5) å†³ç­–åˆ†æ”¯
            # ##############
            if 'emergency' in response[-1]['content'].lower():
                messages = []
                messages.append({
                    'role': 'user',
                    'content': f"Based on the current status of each Traffic Phase, please make the decision. \n{junction_description}."
                })
                response = []
                response_plain_text = ''
                print(f'\n-->Concern Case Agent response:')
                for response in concer_case_decision_agent.run(messages=messages):
                    response_plain_text = typewriter_print(response, response_plain_text)
                response_plain_text = f'-->Mode Select Agent response:\n' + response_plain_text
                append_response_to_file(file_path=_response_txt_file, content=response_plain_text)

                # å°† text è½¬æ¢ä¸º action
                response_dict = json.loads(response[-1]['content'])
                decision, explanation = response_dict['decision'], response_dict['explanation']
                action = extract_action(decision) # å†³ç­–è½¬æ¢ä¸ºåŠ¨ä½œ
            else:
                action = rl_action
                print(f'\n-->Normal Case Agent response:\nRL: {rl_action}')
                
            obs, rewards, dones, infos = env.step(action)

    env.close()